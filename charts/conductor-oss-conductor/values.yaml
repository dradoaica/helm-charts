global:
  # -- Global container image registry override
  imageRegistry: ""
  # -- Global pod image pull secrets
  imagePullSecrets: [ ]

# -- String to partially override the fullname template with a string (will prepend the release name)
nameOverride: ""
# -- String to fully override the fullname template with a string
fullnameOverride: ""

# -- Additional labels to add to all resources
labels: { }
# -- Additional labels to add to pods
podLabels: { }

# -- Annotations to add to all resources
annotations: { }
# -- Additional annotations to add to pods
podAnnotations: { }

# -- Extra init containers to inject into the main Pod spec
extraInitContainers: [ ]
# -- Extra sidecar containers to inject into the main Pod spec
extraContainers: [ ]
# -- Extra volumes to add to the main Pod spec
extraVolumes: [ ]
# -- Extra volume mounts to add to the main container
extraVolumeMounts: [ ]
# -- Extra environment variables to inject into the main container
extraEnvVars: [ ]
# -- Extra envFrom entries to inject into the main container
extraEnvFrom: [ ]
# -- Name of a ConfigMap with extra environment variables to inject into the main container
extraEnvVarsCM: ""
# -- Name of a Secret with extra environment variables to inject into the main container
extraEnvVarsSecret: ""

image:
  # -- Main container image registry
  registry: docker.io
  # -- Main container image repository
  repository: conductoross/conductor
  # -- Main container image tag
  tag: ""
  # -- Main container image pull policy
  pullPolicy: IfNotPresent

serviceAccount:
  # -- Create a dedicated ServiceAccount
  create: true
  # -- Name for the ServiceAccount (autogenerated when empty)
  name: ""
  # -- Additional annotations to add to ServiceAccount
  annotations: { }

# -- Number of old ReplicaSets to retain
revisionHistoryLimit: 10

# -- Deployment update strategy (type only is used)
updateStrategy:
  type: RollingUpdate

# -- Pod priority class name
priorityClassName: ""

# -- Pod termination grace period
terminationGracePeriodSeconds: 60

# -- Pod security context configuration
podSecurityContext:
  # -- Enable pod security context
  enabled: true
  runAsUser: 1001
  runAsGroup: 1001
  runAsNonRoot: true
  fsGroup: 1001

# -- Container security context configuration
containerSecurityContext:
  # -- Enable container security context
  enabled: true
  runAsUser: 1001
  runAsGroup: 1001
  runAsNonRoot: true
  privileged: false
  readOnlyRootFilesystem: false
  allowPrivilegeEscalation: false
  capabilities:
    drop: [ "ALL" ]
  seccompProfile:
    type: "RuntimeDefault"

# -- Main container requests/limits
#  memory calculation: onHeapMB (JVM Heap max size)
#   + maxMetaspaceSizeMB (JVM Metaspace max size)
#   + reservedCodeCacheSizeMB (JVM ReservedCodeCache size)
#   + maxDirectMemorySizeMB (JVM DirectMemory max size)
#   + ~512MB (other overheads; e.g., thread stacks, GC, symbols, etc.)
resources:
  requests:
    cpu: 300m
    memory: 2Gi
  limits:
    cpu: "2"
    memory: 3Gi

# -- Liveness probe configuration
livenessProbe:
  # -- Enable liveness probe
  enabled: true
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 30
  timeoutSeconds: 10
  failureThreshold: 3
  successThreshold: 1

# -- Readiness probe configuration
readinessProbe:
  # -- Enable readiness probe
  enabled: true
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 10
  failureThreshold: 3
  successThreshold: 1

# -- Startup probe configuration
startupProbe:
  # -- Enable startup probe
  enabled: true
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 1
  failureThreshold: 15
  successThreshold: 1

# -- Lifecycle hooks configuration
lifecycleHooks: { }

container:
  # -- Container ports used by the Pod spec and as Service targetPort values
  ports:
    rest: 8080
    ui: 5000
    grpc: 8090

service:
  # -- Service type (ClusterIP, NodePort, LoadBalancer)
  type: ClusterIP
  # -- Service ports used by the Service spec. targetPort fields reference container.ports.*
  ports:
    # -- Service port for REST API
    rest: 8080
    # -- Service port for UI
    ui: 5000
    # -- Service port for gRPC
    grpc: 8090
  nodePorts:
    # -- NodePort value for REST API when service.type is NodePort
    rest: ""
    # -- NodePort value for UI when service.type is NodePort
    ui: ""
    # -- NodePort value for gRPC when service.type is NodePort
    grpc: ""

# -- Node selector
nodeSelector: { }
# -- Node tolerations
tolerations: [ ]
# -- Node affinity
affinity: { }
# -- Topology spread constraints
topologySpreadConstraints: [ ]

networkPolicy:
  # -- Create a NetworkPolicy
  create: false
  # -- Name for the NetworkPolicy (defaults to fullname when empty)
  name: ""
  # -- NetworkPolicy ingress rules
  ingress: [ ]
  # -- NetworkPolicy egress rules
  egress:
    # Allow DNS resolution
    - to:
        - ipBlock: { cidr: 0.0.0.0/0 }
      ports:
        - port: 53
          protocol: UDP
        - port: 53
          protocol: TCP

podDisruptionBudget:
  # -- Create a PodDisruptionBudget for high availability
  create: false
  # -- Minimum number of pods that must be available during disruptions (mutually exclusive with maxUnavailable)
  minAvailable: 1
  # -- Maximum number of pods that can be unavailable during disruptions (mutually exclusive with minAvailable)
  maxUnavailable: ""
  # Alternatively, use maxUnavailable (mutually exclusive with minAvailable)
  # maxUnavailable: "50%"

autoscaling:
  # -- Create a HorizontalPodAutoscaler
  create: false
  # -- Minimum number of replicas
  minReplicas: 1
  # -- Maximum number of replicas
  maxReplicas: 10
  # -- Target CPU utilization percentage
  targetCPUUtilizationPercentage: 80
  # -- Target memory utilization percentage
  targetMemoryUtilizationPercentage: 80

ingress:
  # -- Create an Ingress for external HTTP access
  create: false
  # -- IngressClass that will be used to implement the Ingress
  className: ""
  # -- Additional annotations for the Ingress
  annotations: { }
  # -- List of Ingress hosts with paths for API and UI
  hosts:
    - host: conductor-api.local
      paths:
        - path: /
          pathType: Prefix
          port: 8080
    - host: conductor-ui.local
      paths:
        - path: /
          pathType: Prefix
          port: 5000
  # -- TLS configuration for Ingress
  tls: [ ]

# App specific
# -- Number of pods
replicaCount: 1

memory:
  # -- On-heap memory limit in MB. If set, -Xms and -Xmx will be value. If not set, defaults to 2048
  onHeapMB: ""
  # -- JVM Metaspace max size in MB. If not set, defaults to 256
  maxMetaspaceSizeMB: ""
  # -- JVM ReservedCodeCache size in MB. If not set, defaults to 240
  reservedCodeCacheSizeMB: ""
  # -- JVM G1 Heap region size in MB. If not set, defaults to 1
  g1HeapRegionSizeMB: ""
  # -- JVM DirectMemory max size in MB. If not set, defaults to 256
  maxDirectMemorySizeMB: ""

# -- App configuration
app:
  # -- Name of the stack within which the app is running (e.g., dev, testing, staging, prod)
  stack: ""
  # -- The ID with which the app has been registered (e.g., conductor, myApp)
  appID: ""
  # -- The maximum number of threads to be allocated to the executor service threadpool
  executorServiceMaxThreadCount: ""
  # -- The timeout duration to set when a workflow is pushed to the decider queue (e.g., 30s, 1m)
  workflowOffsetTimeout: ""
  # -- The maximum timeout duration to set when a workflow with a running task is pushed to the decider queue (e.g., 30m, 1h)
  maxPostponeDurationSeconds: ""
  # -- The number of threads to use for background sweeping on active workflows
  sweeperThreadCount: ""
  # -- The timeout for polling workflows to be swept (e.g., 2000ms, 2s)
  sweeperWorkflowPollTimeout: ""
  # -- The number of threads to configure the threadpool in the event processor
  eventProcessorThreadCount: ""
  # -- Whether to enable indexing of messages within event payloads
  eventMessageIndexingEnabled: ""
  # -- Whether to enable indexing of event execution results
  eventExecutionIndexingEnabled: ""
  # -- Whether to enable the workflow execution lock
  workflowExecutionLockEnabled: true
  # -- The time for which the lock is leased (e.g., 60000ms, 1m)
  lockLeaseTime: ""
  # -- The time for which the thread will block in an attempt to acquire the lock (e.g., 500ms, 1s)
  lockTimeToTry: 500
  # -- The time to consider if a worker is actively polling for a task (e.g., 10s)
  activeWorkerLastPollTimeout: ""
  # -- The time for which a task execution will be postponed if rate-limited or concurrent execution limited (e.g., 60s)
  taskExecutionPostponeDuration: ""
  # -- Whether to enable indexing of tasks
  taskIndexingEnabled: ""
  # -- Whether to enable indexing of task execution logs
  taskExecLogIndexingEnabled: ""
  # -- Whether to enable asynchronous indexing to Elasticsearch
  asyncIndexingEnabled: ""
  # -- The number of threads in the threadpool for system task workers
  systemTaskWorkerThreadCount: 20
  # -- The maximum number of threads to be polled within the threadpool for system task workers
  systemTaskMaxPollCount: 20
  # -- The interval after which a system task will be checked by the system task worker for completion (e.g., 30s)
  systemTaskWorkerCallbackDuration: ""
  # -- The interval at which system task queues will be polled by system task workers (e.g., 50ms)
  systemTaskWorkerPollInterval: ""
  # -- The namespace for the system task workers to provide instance-level isolation
  systemTaskWorkerExecutionNamespace: ""
  # -- The number of threads to be used within the threadpool for system task workers in each isolation group
  isolatedSystemTaskWorkerThreadCount: ""
  # -- The duration of workflow execution qualifying as short-running when async indexing to Elasticsearch is enabled (e.g., 30s)
  asyncUpdateShortRunningWorkflowDuration: "10m"
  # -- The delay with which short-running workflows will be updated in Elasticsearch when async indexing is enabled (e.g., 60s)
  asyncUpdateDelay: ""
  # -- Whether to validate the owner email field as mandatory within workflow and task definitions
  ownerEmailMandatory: ""
  # -- The number of threads used in the Scheduler for polling events from multiple event queues
  eventQueueSchedulerPollThreadCount: ""
  # -- The time interval at which the default event queues will be polled (e.g., 100ms)
  eventQueuePollInterval: ""
  # -- The number of messages to be polled from a default event queue in a single operation
  eventQueuePollCount: ""
  # -- The timeout for the poll operation on the default event queue (e.g., 1000ms)
  eventQueueLongPollTimeout: ""
  # -- Whether to enable workflow/task definition name validation
  workflowNameValidationEnabled: false
  # -- Whether to enable summary input/output JSON serialization
  summaryInputOutputJsonSerializationEnabled: ""
  # -- The threshold of the workflow input payload size beyond which the payload will be stored in ExternalPayloadStorage
  workflowInputPayloadSizeThreshold: "1MB"
  # -- The maximum threshold of the workflow input payload size beyond which input will be rejected and the workflow marked as FAILED
  maxWorkflowInputPayloadSizeThreshold: "4GB"
  # -- The threshold of the workflow output payload size beyond which the payload will be stored in ExternalPayloadStorage
  workflowOutputPayloadSizeThreshold: "1MB"
  # -- The maximum threshold of the workflow output payload size beyond which output will be rejected and the workflow marked as FAILED
  maxWorkflowOutputPayloadSizeThreshold: "4GB"
  # -- The threshold of the task input payload size beyond which the payload will be stored in ExternalPayloadStorage
  taskInputPayloadSizeThreshold: "1MB"
  # -- The maximum threshold of the task input payload size beyond which the task input will be rejected and the task marked as FAILED_WITH_TERMINAL_ERROR
  maxTaskInputPayloadSizeThreshold: "4GB"
  # -- The threshold of the task output payload size beyond which the payload will be stored in ExternalPayloadStorage
  taskOutputPayloadSizeThreshold: "1MB"
  # -- The maximum threshold of the task output payload size beyond which the task output will be rejected and the task marked as FAILED_WITH_TERMINAL_ERROR
  maxTaskOutputPayloadSizeThreshold: "4GB"
  # -- The maximum threshold of the workflow variables payload size beyond which the task changes will be rejected and the task marked as FAILED_WITH_TERMINAL_ERROR
  maxWorkflowVariablesPayloadSizeThreshold: "100MB"
  # -- The maximum size of task execution logs
  taskExecLogSizeLimit: ""
  # -- Whether to enable the workflow repair service
  workflowRepairServiceEnabled: false
  # -- Whether to enable the remove Redis key feature
  enableRemoveRedisKey: false
  # -- TTL for Redis key expiration
  ttlRedisKeyExpire: ""

# -- DB configuration
db:
  # -- DB type (redis_standalone, redis_cluster, redis_sentinel, mysql, postgres, memory)
  type: redis_standalone

# -- Queue configuration
queue:
  # -- Queue type (redis_standalone, redis_cluster, redis_sentinel, postgres, memory)
  type: redis_standalone

# -- Default event queue configuration
defaultEventQueue:
  # -- The default event queue type (e.g., amqp, nats_stream, kafka)
  type: "amqp"

# -- Queues configuration
queues:
  # -- Number of threads allocated to Dynomite queues
  dynomiteThreads: 10

# -- Workflow execution lock configuration
workflowExecutionLock:
  # -- Workflow execution lock type (redis, postgres, local_only, noop_lock)
  type: redis

# -- Indexing configuration
indexing:
  # -- Enable indexing
  enabled: true
  # -- Indexing type (elasticsearch, opensearch, postgres, memory)
  type: elasticsearch

# -- External payload storage configuration
externalPayloadStorage:
  # -- External payload storage type (postgres, null)
  type: null

# -- Workflow archival configuration
workflowArchival:
  # -- Enable workflow archival
  enabled: false
  # -- Archival type (e.g., elasticsearch, opensearch)
  type: "elasticsearch"
  # -- Time to live for archived workflows
  ttl: "30d"
  # -- Delay before archiving a completed workflow
  delay: "1h"

# -- Redis configuration
redis:
  # -- Redis host
  host: ""
  # -- Redis port
  port: 6379
  # -- List of redis hosts (host:port). Overrides host/port if set
  hosts: ""
  # -- Redis Sentinel master name
  masterName: ""
  # -- Enable SSL/TLS
  ssl: false
  # -- Redis password
  password: ""
  # -- Task definition cache refresh interval
  taskDefCacheRefreshInterval: 1
  # -- Workflow namespace prefix
  workflowNamespacePrefix: "conductor"
  # -- Queue namespace prefix
  queueNamespacePrefix: "conductor_queues"
  # -- Non-quorum port used to connect to local Redis (used by Dynomite queues)
  queuesNonQuorumPort: 22122
  # -- Availability zone/rack for the Redis node
  availabilityZone: "us-east-1c"
  # -- Maximum idle connections in the pool
  maxIdleConnections: ""
  # -- Minimum idle connections in the pool
  minIdleConnections: ""
  # -- Minimum time an idle connection can sit in the pool before eviction (ms)
  minEvictableIdleTimeMillis: ""
  # -- Time between eviction runs (ms, -1 to disable)
  timeBetweenEvictionRunsMillis: ""
  # -- Whether to validate connections while idle
  testWhileIdle: ""
  # -- Number of connections to test per eviction run
  numTestsPerEvictionRun: ""

# -- Elasticsearch configuration
elasticsearch:
  # -- Elasticsearch URL
  url: ""
  # -- Elasticsearch username
  username: ""
  # -- Elasticsearch password
  password: ""
  # -- Elasticsearch index name
  indexName: ""
  # -- Elasticsearch index prefix
  indexPrefix: ""
  # -- Elasticsearch index replicas count
  indexReplicasCount: 0
  # -- Elasticsearch version
  version: 7
  # -- Elasticsearch cluster health color
  clusterHealthColor: yellow
  # -- Elasticsearch REST client connection timeout
  restClientConnectionTimeout: 5000
  # -- Elasticsearch REST client read timeout
  restClientReadTimeout: 30000

# -- MySQL configuration
mySQL:
  # -- MySQL host
  host: ""
  # -- MySQL port
  port: 3306
  # -- MySQL username
  username: ""
  # -- MySQL password
  password: ""
  # -- MySQL database name
  database: ""

# -- PostgreSQL configuration
postgres:
  # -- PostgreSQL host
  host: ""
  # -- PostgreSQL port
  port: 5432
  # -- PostgreSQL username
  username: ""
  # -- PostgreSQL password
  password: ""
  # -- PostgreSQL database name
  database: ""
  # -- External payload storage configuration for PostgreSQL
  externalPayloadStorage:
    # -- Conductor URL
    conductorUrl: ""
    # -- Table name
    tableName: "external.external_payload"
    # -- Max data rows
    maxDataRows: 9223372036854775807
    # -- Max data days
    maxDataDays: 0
    # -- Max data months
    maxDataMonths: 0
    # -- Max data years
    maxDataYears: 1

# -- OpenSearch configuration
openSearch:
  # -- OpenSearch URL
  url: ""
  # -- OpenSearch username
  username: ""
  # -- OpenSearch password
  password: ""
  # -- OpenSearch index name
  indexName: ""
  # -- OpenSearch index prefix
  indexPrefix: ""
  # -- OpenSearch index replicas count
  indexReplicasCount: 0
  # -- OpenSearch version
  version: 0
  # -- OpenSearch cluster health color
  clusterHealthColor: green
  # -- OpenSearch REST client connection timeout
  restClientConnectionTimeout: 5000
  # -- OpenSearch REST client read timeout
  restClientReadTimeout: 30000

# -- AMQP (RabbitMQ) Event Queues configuration
amqpEventQueues:
  # -- Enable AMQP event queue support
  enabled: false
  # -- RabbitMQ server host(s)
  hosts: ""
  # -- RabbitMQ username
  username: ""
  # -- RabbitMQ password
  password: ""
  # -- RabbitMQ virtual host
  virtualHost: "/"
  # -- RabbitMQ port
  port: 5672
  # -- Whether to use NIO
  useNio: false
  # -- Batch size for message consumption
  batchSize: 1
  # -- Poll time duration (e.g., 100ms)
  pollTimeDuration: "100ms"
  # -- Queue type (classic, quorum)
  queueType: "classic"
  # -- Whether to process messages sequentially
  sequentialMsgProcessing: true
  # -- Connection timeout in ms
  connectionTimeoutInMilliSecs: 180000
  # -- Network recovery interval in ms
  networkRecoveryIntervalInMilliSecs: 5000
  # -- Heartbeat timeout in seconds
  requestHeartbeatTimeoutInSecs: 30
  # -- Handshake timeout in ms
  handshakeTimeoutInMilliSecs: 180000
  # -- Maximum channel count
  maxChannelCount: 5000
  # -- Rate limit
  limit: 50
  # -- Rate limit duration in ms
  duration: 1000
  # -- Retry type (REGULARINTERVALS, EXPONENTIALBACKOFF)
  retryType: "REGULARINTERVALS"
  # -- Whether to use exchange (true) or queue (false)
  useExchange: true
  # -- Listener queue prefix
  listenerQueuePrefix: ""
  # -- Whether queues are durable
  durable: false
  # -- Whether queues are exclusive
  exclusive: false
  # -- Max priority for messages (-1 to disable)
  maxPriority: -1

# -- NATS Event Queues configuration
natsEventQueues:
  # -- Enable NATS event queue support
  enabled: false
  natsStream:
    # -- NATS streaming cluster ID
    clusterID: "test-cluster"
    # -- NATS streaming durable name
    durableName: ""
    # -- NATS streaming URL
    url: "nats://localhost:4222"
    # -- Listener queue prefix
    listenerQueuePrefix: ""

# -- Kafka Event Queues configuration
kafkaEventQueues:
  # -- Enable Kafka event queue support
  enabled: false
  # -- Kafka bootstrap servers
  bootstrapServers: "kafka:29092"
  # -- Dead letter queue topic
  dlqTopic: "conductor-dlq"
  # -- Listener queue prefix
  listenerQueuePrefix: "conductor_"
  # -- Poll time duration (e.g., 500ms)
  pollTimeDuration: "500ms"
  # -- Kafka consumer client properties
  consumer: { }
  # -- Kafka producer client properties
  producer: { }
  # -- Kafka admin client properties
  admin: { }

# -- Status listener configuration (webhook notifications)
statusListener:
  # -- Workflow status listener type (e.g., workflow_publisher)
  workflowType: ""
  # -- Task status listener type (e.g., task_publisher)
  taskType: ""

# -- Status notifier configuration
statusNotifier:
  # -- Webhook notification URL
  url: ""
  # -- Webhook endpoint for workflow status
  endpointWorkflow: ""
  # -- Webhook endpoint for task status
  endpointTask: ""
  # -- Subscribed task statuses (e.g., SCHEDULED)
  subscribedTaskStatuses: ""
  # -- Custom header name
  headerPrefer: ""
  # -- Custom header value
  headerPreferValue: ""
  # -- Connection timeout in ms
  requestTimeoutMsConnect: ""
  # -- Read timeout in ms
  requestTimeoutMsRead: ""
  # -- Connection manager timeout in ms
  requestTimeoutMsConnMgr: ""
  # -- Number of retries
  requestRetryCount: ""
  # -- Retry interval in ms
  requestRetryIntervalMs: ""
  # -- Max concurrent requests
  connectionPoolMaxRequest: ""
  # -- Max concurrent requests per route
  connectionPoolMaxRequestPerRoute: ""

# -- AI configuration
ai:
  enabled: true
  # -- OpenAI configuration
  openAI:
    # -- OpenAI API Key
    apiKey: ""
    # -- OpenAI Organization ID
    organizationID: ""
  # -- Anthropic configuration
  anthropic:
    # -- Anthropic API Key
    apiKey: ""
  # -- Mistral configuration
  mistral:
    # -- Mistral API Key
    apiKey: ""
  # -- Cohere configuration
  cohere:
    # -- Cohere API Key
    apiKey: ""
  # -- Grok configuration
  grok:
    # -- Grok API Key
    apiKey: ""
  # -- Perplexity configuration
  perplexity:
    # -- Perplexity API Key
    apiKey: ""
  # -- HuggingFace configuration
  huggingFace:
    # -- HuggingFace API Key
    apiKey: ""
  # -- StabilityAI configuration
  stabilityAI:
    # -- StabilityAI API Key
    apiKey: ""
  # -- Azure OpenAI configuration
  azureOpenAI:
    # -- Azure OpenAI API Key
    apiKey: ""
    # -- Azure OpenAI Base URL
    baseUrl: ""
    # -- Azure OpenAI Deployment Name
    deploymentName: ""
  # -- AWS Bedrock configuration
  bedrock:
    # -- AWS Access Key ID
    accessKey: ""
    # -- AWS Secret Access Key
    secretKey: ""
    # -- AWS Region
    region: "us-east-1"
  # -- Google Gemini configuration
  gemini:
    # -- Google Cloud Project ID
    projectID: ""
    # -- Google Cloud Location
    location: "us-central1"
  # -- Ollama configuration
  ollama:
    # -- Ollama Base URL
    baseUrl: "http://localhost:11434"

# -- Metrics configuration
metrics:
  # -- Enable metrics logging
  loggerEnabled: false
  # -- Metrics logging a report period in seconds
  loggerReportPeriodSeconds: 1
  # -- Enable Prometheus metrics
  prometheusEnabled: false

# -- Management configuration
management:
  # -- Enable Redis health check
  healthRedisEnabled: true
  # -- Actuator endpoints to expose (comma-separated)
  endpointsWebExposureInclude: "health,info,metrics,prometheus"
  # -- Request metrics percentiles (comma-separated)
  metricsPercentiles: "0.50,0.75,0.90,0.95,0.99"
  # -- Health endpoint detail level (never, when_authorized, always)
  healthShowDetails: "always"
  # -- Metrics export backends
  metricsExport:
    # -- Enable Atlas metrics export
    atlas: false
    # -- Enable OTLP metrics export
    otlp: false
    # -- Enable Influx metrics export
    influx: false
    # -- Enable Elastic metrics export
    elastic: false
    # -- Enable Dynatrace metrics export
    dynatrace: false
    # -- Enable New Relic metrics export
    newRelic: false
    # -- Enable Stackdriver metrics export
    stackdriver: false
    # -- Stackdriver Project ID
    stackdriverProjectID: ""
    # -- Enable Datadog metrics export
    datadog: false
    # -- Datadog API Key
    datadogApiKey: ""
    # -- Enable StatsD metrics export
    statsD: false
    # -- Enable CloudWatch metrics export
    cloudWatch: false
    # -- CloudWatch Namespace
    cloudWatchNamespace: "conductor"
    # -- Enable Azure Monitor metrics export
    azureMonitor: false
    # -- Azure Monitor Instrumentation Key
    azureMonitorInstrumentationKey: ""
    # -- Enable JMX metrics export
    jmx: false

# -- GRPC Server configuration
grpcServer:
  # -- Enable GRPC server
  enabled: true

# -- CORS configuration
cors:
  # -- Allowed origins for CORS (comma-separated, or * for all)
  allowedOrigins: "*"

# -- Security configuration (IAM/Auth)
security:
  # -- Enable security
  enabled: false
  auth:
    oidc:
      # -- Enable OIDC authentication
      enabled: false
      # -- OIDC Discovery URI
      discoveryUri: ""
      # -- OIDC Client ID
      clientID: ""
      # -- OIDC Client Secret (can be provided via secret)
      clientSecret: ""
      # -- OIDC Audience
      audience: ""
      # -- OIDC Groups Claim
      groupsClaim: "groups"
    basic:
      # -- Enable Basic authentication
      enabled: false
      # -- Basic Auth Realm
      realm: ""
      # -- Basic Auth Principal
      principal: ""
      # -- Basic Auth Role
      role: ""

# -- Spring configuration
spring:
  # -- Profiles passed via SPRING_PROFILES_ACTIVE
  profilesActive: "logrotate"
  # -- Path to the API docs endpoint
  apiDocsPath: "/api-docs"

# -- Logging configuration
logging:
  level:
    # -- Root log level
    root: INFO

# -- Environment variables
env:
  EXTRA_JVM_OPTS: ""
